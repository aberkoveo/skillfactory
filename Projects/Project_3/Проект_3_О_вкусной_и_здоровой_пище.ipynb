{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597662709714",
   "display_name": "Python 3.8.3 64-bit ('anaconda3': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import re\n",
    "import ast\n",
    "\n",
    "# from pandas_profiling import ProfileReport\n",
    "\n",
    "import my_functions\n",
    "import importlib\n",
    "importlib.reload(my_functions)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_folder = 'input//'\n",
    "print(os.listdir(\"input\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA\n",
    "### main_task.csv - оригинальные данные\n",
    "### kaggle_task.csv - данные добавленные для соревнование на площаке kaggle для тестирования модели\n",
    "### sample_submission.csv - результаты для проверки модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(input_folder + 'main_task.csv')\n",
    "data_kaggle = pd.read_csv(input_folder + 'kaggle_task.csv')\n",
    "sample_submission = pd.read_csv(input_folder + '/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# дря корректной обработки признаков объединяем трейн и тест в один датасет\n",
    "data['sample'] = 1 # помечаем где у нас трейн\n",
    "data_kaggle['sample'] = 0 # помечаем где у нас тест\n",
    "data_kaggle['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n",
    "\n",
    "data = data_kaggle.append(data, sort=False).reset_index(drop=True) # объединяем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Первоначальная версия датасета состоит из десяти столбцов, содержащих следующую информацию:\n",
    "* Restaurant_id — идентификационный номер ресторана / сети ресторанов;\n",
    "* City — город, в котором находится ресторан;\n",
    "* Cuisine Style — кухня или кухни, к которым можно отнести блюда, предлагаемые в ресторане;\n",
    "* Ranking — место, которое занимает данный ресторан среди всех ресторанов своего города;\n",
    "* Rating — рейтинг ресторана по данным TripAdvisor (именно это значение должна будет предсказывать модель);\n",
    "* Price Range — диапазон цен в ресторане;\n",
    "* Number of Reviews — количество отзывов о ресторане;\n",
    "* Reviews — данные о двух отзывах, которые отображаются на сайте ресторана;\n",
    "* URL_TA — URL страницы ресторана на TripAdvosor;\n",
    "* ID_TA — идентификатор ресторана в базе данных TripAdvisor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.columns = data.columns.str.lower()\n",
    "data.columns = [name.replace(' ', '_') for name in data.columns]\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['cuisine_style'] = data['cuisine_style'].fillna('[\\'not_specified\\']')\n",
    "data['Number_of_Reviews_isNAN'] = pd.isna(data.number_of_reviews).astype('uint8')\n",
    "data['number_of_reviews'] = data.groupby(by='city').number_of_reviews.apply(lambda x: x.fillna(round(x.mean())))\n",
    "data['price_range'].fillna(data.price_range.mode()[0], inplace=True)\n",
    "data.reviews.fillna(\"[[], []]\",inplace=True)\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.drop(['restaurant_id', 'url_ta', 'id_ta'], inplace=True,  axis = 1, errors='ignore')\n",
    "data['cuisine_style'] = data['cuisine_style'].apply(ast.literal_eval)\n",
    "data['reviews'] = data['reviews'].apply(lambda x: re.sub((r'\\bnan\\b'), '\\'empty_voice\\'', x))\n",
    "data['reviews'] = data['reviews'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выбросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ranking.hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обогащаем новыми признаками "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data['reviews_text'] =  data['reviews'].apply(lambda x: x[0])\n",
    "data['reviews_dates'] = data['reviews'].apply(lambda x: [datetime.strptime(date, '%m/%d/%Y').date() for date in x[1]])\n",
    "data['price_range_int'] = data.price_range.apply(lambda x: 1 if x == '$' else \n",
    "                                                              (2 if x == '$$ - $$$' else 3))\n",
    "data['review_text_tone_coef'] = data['reviews_text'].apply(lambda x: my_functions.review_text_tone(x))\n",
    "\n",
    "set_dates = set()\n",
    "data['dif_days'] = data.reviews_dates.apply(lambda x: (x[0] - x[-1]) if len(x) > 0 else pd.Timedelta('0 days') ).dt.days\n",
    "\n",
    "last_date = set()\n",
    "data.reviews_dates.apply(lambda x: last_date.update(x))\n",
    "data['diff_last_date'] = data.reviews_dates.apply(my_functions.diff_today)\n",
    "\n",
    "\n",
    "cuisine_style_set = set()\n",
    "data.cuisine_style.apply(lambda x: cuisine_style_set.update(x))\n",
    "cuisine_style_list = list(cuisine_style_set)\n",
    "for cuisine in cuisine_style_list:\n",
    "    data[cuisine] = data.cuisine_style.apply(lambda x: 1 if cuisine in x else 0)\n",
    "\n",
    "data['city_orig'] = data['city'] \n",
    "data = pd.get_dummies(data, columns=['city_orig'], dummy_na=True, drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_set = set()\n",
    "# data.reviews_dates.apply(lambda x: date_set.update(x))\n",
    "# last_date = max(date_set)\n",
    "# data['diff_last_date'] = data.reviews_dates.apply(lambda x: (max([(x_i - last_date).days for x_i in x ]) if len(x) > 0 else pd.Timedelta('0 days').days ))\n",
    "# data['diff_last_date']\n",
    "\n",
    "\n",
    "# data.city.apply(lambda x: len(data[data.city == x]))\n",
    "\n",
    "city_dict = data.groupby(by='city').city.size()\n",
    "# data['quan_in_city'] = data.city.apply(lambda x: len(data[data.city == x]))\n",
    "data['ranking_for_city'] =  data['ranking']  - data.city.apply(lambda x: city_dict[x])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормируем признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ranking_norm_by_city'] = data.groupby('city').ranking.transform(lambda x: (x - x.mean()) / x.std())\n",
    "data['number_of_reviews_norm'] = data.number_of_reviews.apply(lambda x: (x - data.number_of_reviews.mean()) / data.number_of_reviews.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['quan_in_city'] = data.city.apply(lambda x: len(data[data.city == x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data['review_text_tone_coef'] = data['reviews_text'].apply(lambda x: my_functions.review_text_tone(x))\n",
    "\n",
    "# data['review_text_tone_coef'].value_counts()\n",
    "# data['good_reviews'] = data.review_text_tone_coef.apply(lambda x: 1 if x > 1 else 0)\n",
    "# data['bad_reviews'] = data.review_text_tone_coef.apply(lambda x: 1 if x < -1 else 0)\n",
    "\n",
    "\n",
    "# data['quan_in_city'] = data.city.apply(lambda x: data[data.city == x].size)\n",
    "\n",
    "\n",
    "# datetime.today().date()\n",
    "\n",
    "#data.iloc[:2].reviews_dates.apply(max)\n",
    "# data[data.city == 'London'].ranking_mean_by_city\n",
    "# data['review_text_tone_coef'].value_counts()\n",
    "# data['ranking_by_reviews'] = data.ranking_by_reviews.apply(lambda x: (x - data.ranking_by_reviews.mean()) / data.ranking_by_reviews.std())\n",
    "# data['ranking_by_reviews']\n",
    "# data['ranking_by_reviews'].value_counts(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10,7)\n",
    "\n",
    "top10_city = data.city.value_counts()[0:10].index\n",
    "for city in top10_city:\n",
    "    data[data.city == city].ranking.hist(bins=100, label=city)\n",
    "    plt.legend()\n",
    "data.groupby(by='city').number_of_reviews.mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.city == 'London'].ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.city.value_counts(ascending=True).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(by='city').agg({'ranking':'mean', 'rating': 'mean', 'number_of_reviews': 'mean'}).hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data.price_range.value_counts(dropna=False)\n",
    "\n",
    "# data.groupby(by='city').agg({'price_range_int':'mean', 'city':'size'}).sort_values(by='price_range_int')\n",
    "# data['price_range'] = data['price_range'].astype(str)\n",
    "# data.groupby(by='price_range').agg({'city':lambda x: stats.mode(x) , 'ranking': 'mean', 'rating' : 'mean', 'number_of_reviews':'mean', 'dif_days':'mean'})\n",
    "\n",
    "correlation = data[['rating','ranking',  'number_of_reviews', 'dif_days',\n",
    "                    #'ranking_by_reviews',\n",
    "                    'ranking_for_city',\n",
    "                    'ranking_norm_by_city',\n",
    "                    'price_range_int',\n",
    "                    'number_of_reviews_norm',\n",
    "                    'dif_days'\n",
    "                    ]].corr()\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.drop(['number_of_reviews'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.query('sample == 1').drop(['sample'], axis=1)\n",
    "test_data = data.query('sample == 0').drop(['sample'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Загружаем специальный инструмент для разбивки:\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Импортируем необходимые библиотеки:\n",
    "from sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\n",
    "from sklearn import metrics # инструменты для оценки точности модели\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Наборы данных с меткой \"train\" будут использоваться для обучения модели, \"test\" - для тестирования.\n",
    "# Для тестирования мы будем использовать 25% от исходного датасета.\n",
    "# Х - данные с информацией о ресторанах, у - целевая переменная (рейтинги ресторанов)\n",
    "\n",
    "X = train_data.drop(['restaurant_id','city', 'city_orig', 'rating', 'cuisine_style', 'price_range', \n",
    "               'reviews', 'url_ta', 'id_ta', 'reviews_text',\n",
    "               #'ranking',\n",
    "               #'ranking_for_city',\n",
    "               'number_of_reviews',\n",
    "               'reviews_dates'\n",
    "               ], \n",
    "               axis = 1, errors='ignore')\n",
    "\n",
    "\n",
    "y = train_data['rating']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "# Создаём модель\n",
    "regr = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)\n",
    "\n",
    "# Обучаем модель на тестовом наборе данных\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n",
    "# Предсказанные значения записываем в переменную y_pred\n",
    "y_pred = regr.predict(X_test)\n",
    "plt.rcParams['figure.figsize'] = (10,10)\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(15).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n",
    "# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE: 0.20900624999999998  \n",
    "MAE: 0.20914499999999997  \n",
    "MAE: 0.2097025   \n",
    "MAE: 0.209354375  \n",
    "MAE: 0.20936249999999998  \n",
    "MAE: 0.20936249999999998   \n",
    "MAE: 0.20969625000000003  \n",
    "MAE: 0.210050625  \n",
    "MAE: 0.21450125  \n",
    "0.21451624999999996  \n",
    "MAE: 0.21875124999999998  \n",
    "MAE: 0.2084305  \n",
    "MAE: 0.210808  \n",
    "0.2131725  \n",
    "MAE: 0.2148355  \n",
    "MAE: 0.21277599999999997  \n",
    "MAE: 0.2086605   \n",
    "MAE: 0.34141057440476186"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPOCESSING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(input_folder + 'main_task.csv')\n",
    "data_kaggle = pd.read_csv(input_folder + 'kaggle_task.csv')\n",
    "sample_submission = pd.read_csv(input_folder + '/sample_submission.csv')\n",
    "\n",
    "# дря корректной обработки признаков объединяем трейн и тест в один датасет\n",
    "data['sample'] = 1 # помечаем где у нас трейн\n",
    "data_kaggle['sample'] = 0 # помечаем где у нас тест\n",
    "data_kaggle['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n",
    "\n",
    "data = data_kaggle.append(data, sort=False).reset_index(drop=True) # объединяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_data = my_functions.prepoc_data(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       ranking  sample  rating  Number_of_Reviews_isNAN  price_range_int  \\\n0      12963.0       0     0.0                        0                2   \n1        106.0       0     0.0                        0                2   \n2        810.0       0     0.0                        0                2   \n3       1669.0       0     0.0                        0                3   \n4         37.0       0     0.0                        0                3   \n...        ...     ...     ...                      ...              ...   \n49995    500.0       1     4.5                        0                2   \n49996   6341.0       1     3.5                        0                2   \n49997   1652.0       1     4.5                        0                2   \n49998    641.0       1     4.0                        0                2   \n49999   4827.0       1     3.0                        0                2   \n\n       review_text_tone_coef  dif_days  diff_last_date  Fujian  Portuguese  \\\n0                          0         0               0       0           0   \n1                          1        37             986       0           0   \n2                          0        22             963       0           0   \n3                          0        14             985       0           0   \n4                          3        15             921       0           0   \n...                      ...       ...             ...     ...         ...   \n49995                      1        34             975       0           0   \n49996                      0         9             970       0           0   \n49997                      0      3127            1383       0           0   \n49998                      0        23            1133       0           0   \n49999                      1      1306            1660       0           0   \n\n       ...  city_orig_Prague  city_orig_Rome  city_orig_Stockholm  \\\n0      ...                 0               0                    0   \n1      ...                 0               0                    0   \n2      ...                 0               0                    0   \n3      ...                 0               0                    0   \n4      ...                 0               0                    0   \n...    ...               ...             ...                  ...   \n49995  ...                 0               0                    0   \n49996  ...                 0               0                    0   \n49997  ...                 0               0                    1   \n49998  ...                 0               0                    0   \n49999  ...                 0               0                    0   \n\n       city_orig_Vienna  city_orig_Warsaw  city_orig_Zurich  city_orig_nan  \\\n0                     0                 0                 0              0   \n1                     0                 0                 0              0   \n2                     0                 0                 0              0   \n3                     0                 0                 0              0   \n4                     0                 0                 0              0   \n...                 ...               ...               ...            ...   \n49995                 0                 0                 0              0   \n49996                 0                 0                 0              0   \n49997                 0                 0                 0              0   \n49998                 0                 1                 0              0   \n49999                 0                 0                 0              0   \n\n       ranking_for_city  ranking_norm_by_city  number_of_reviews_norm  \n0                6855.0              1.491224               -0.420617  \n1                -369.0             -1.404530               -0.094045  \n2                  65.0             -0.146058               -0.336340  \n3               -5524.0             -1.376113                0.274665  \n4                -343.0             -1.673120                0.134204  \n...                 ...                   ...                     ...  \n49995           -2194.0             -1.448276               -0.157253  \n49996             233.0             -0.147913                1.468583  \n49997             619.0              0.573818               -0.420617  \n49998            -284.0             -0.663243               -0.188856  \n49999            2133.0              0.956414                0.478333  \n\n[50000 rows x 169 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ranking</th>\n      <th>sample</th>\n      <th>rating</th>\n      <th>Number_of_Reviews_isNAN</th>\n      <th>price_range_int</th>\n      <th>review_text_tone_coef</th>\n      <th>dif_days</th>\n      <th>diff_last_date</th>\n      <th>Fujian</th>\n      <th>Portuguese</th>\n      <th>...</th>\n      <th>city_orig_Prague</th>\n      <th>city_orig_Rome</th>\n      <th>city_orig_Stockholm</th>\n      <th>city_orig_Vienna</th>\n      <th>city_orig_Warsaw</th>\n      <th>city_orig_Zurich</th>\n      <th>city_orig_nan</th>\n      <th>ranking_for_city</th>\n      <th>ranking_norm_by_city</th>\n      <th>number_of_reviews_norm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12963.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6855.0</td>\n      <td>1.491224</td>\n      <td>-0.420617</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>106.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>37</td>\n      <td>986</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-369.0</td>\n      <td>-1.404530</td>\n      <td>-0.094045</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>810.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>22</td>\n      <td>963</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>65.0</td>\n      <td>-0.146058</td>\n      <td>-0.336340</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1669.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>14</td>\n      <td>985</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-5524.0</td>\n      <td>-1.376113</td>\n      <td>0.274665</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>37.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>15</td>\n      <td>921</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-343.0</td>\n      <td>-1.673120</td>\n      <td>0.134204</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>500.0</td>\n      <td>1</td>\n      <td>4.5</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>34</td>\n      <td>975</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-2194.0</td>\n      <td>-1.448276</td>\n      <td>-0.157253</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>6341.0</td>\n      <td>1</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>9</td>\n      <td>970</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>233.0</td>\n      <td>-0.147913</td>\n      <td>1.468583</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>1652.0</td>\n      <td>1</td>\n      <td>4.5</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3127</td>\n      <td>1383</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>619.0</td>\n      <td>0.573818</td>\n      <td>-0.420617</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>641.0</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>23</td>\n      <td>1133</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-284.0</td>\n      <td>-0.663243</td>\n      <td>-0.188856</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>4827.0</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1306</td>\n      <td>1660</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2133.0</td>\n      <td>0.956414</td>\n      <td>0.478333</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows × 169 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "preproc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь выделим тестовую часть\n",
    "train_data = preproc_data.query('sample == 1').drop(['sample'], axis=1)\n",
    "test_data = preproc_data.query('sample == 0').drop(['sample'], axis=1)\n",
    "\n",
    "y = train_data.rating.values            # наш таргет\n",
    "X = train_data.drop(['rating'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.4s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   31.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MAE: 0.20989499999999997\n"
    }
   ],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(['rating'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
    }
   ],
   "source": [
    "predict_submission = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  Restaurant_id  Rating\n0          id_0   3.050\n1          id_1   4.310\n2          id_2   4.380\n3          id_3   4.290\n4          id_4   4.440\n5          id_5   4.310\n6          id_6   1.340\n7          id_7   2.775\n8          id_8   4.005\n9          id_9   4.695",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Restaurant_id</th>\n      <th>Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id_0</td>\n      <td>3.050</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id_1</td>\n      <td>4.310</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id_2</td>\n      <td>4.380</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id_3</td>\n      <td>4.290</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id_4</td>\n      <td>4.440</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>id_5</td>\n      <td>4.310</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>id_6</td>\n      <td>1.340</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>id_7</td>\n      <td>2.775</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>id_8</td>\n      <td>4.005</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>id_9</td>\n      <td>4.695</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "sample_submission['Rating'] = predict_submission\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission.head(10)"
   ]
  }
 ]
}